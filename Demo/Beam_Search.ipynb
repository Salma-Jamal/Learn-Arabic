{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beam_Search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRMtrNoEHQTjTRyaVnjMxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salmaag/Learn-Arabic/blob/main/Demo/Beam_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq1zRHibyPp1"
      },
      "source": [
        "from math import tanh\r\n",
        "from numpy import array\r\n",
        "from numpy import argmax\r\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsrcYSb0yUYC"
      },
      "source": [
        "def sigmoid(x):\r\n",
        "  return 1/(1 + np.exp(-x)) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpTo0-Q-yOY4"
      },
      "source": [
        "def test(model, test_loader, max_text_length):\r\n",
        "  k= 3\r\n",
        "  model.eval()\r\n",
        "  predictslmao = []\r\n",
        "  gt = []\r\n",
        "  imgs = []\r\n",
        "\r\n",
        "  class Breakit(Exception): pass\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    for batch in  tqdm_notebook(test_loader):\r\n",
        "      output_sequences = [([], 0.0)]\r\n",
        "      src, trg = batch\r\n",
        "      imgs.append(src.flatten(0,1))\r\n",
        "      src, trg = src.cuda(), trg.cuda()            \r\n",
        "      memory = get_memory(model,src.float())\r\n",
        "      out_indexes = [None] * k\r\n",
        "      allScores = [None] * k\r\n",
        "      for l in range(k):\r\n",
        "        out_indexes[l] = [tokenizer.chars.index('SOS'), ]\r\n",
        "        allScores[l] = [0.0]\r\n",
        "      mask = model.generate_square_subsequent_mask(1).to('cuda')\r\n",
        "      trg_tensor = torch.LongTensor(out_indexes[0]).unsqueeze(1).to(device)\r\n",
        "      outputfirst = model.vocab(model.transformer.decoder(model.query_pos(model.decoder(trg_tensor)), memory,tgt_mask=mask))\r\n",
        "      mean = torch.mean(outputfirst[0][0])\r\n",
        "      std = torch.std(outputfirst[0][0])            \r\n",
        "      outputfirst = torch.tensor([((x.item()) - mean.item()) / (std.item()) for x in outputfirst[0][0]])\r\n",
        "      try:\r\n",
        "        for i in range(100):\r\n",
        "          list2 = []\r\n",
        "          if i != 0:\r\n",
        "            outputs = []\r\n",
        "            mask = model.generate_square_subsequent_mask(i + 1).to('cuda')\r\n",
        "            for iter in range(k):\r\n",
        "              trg_tensor = torch.LongTensor(out_indexes[iter]).unsqueeze(1).to(device)\r\n",
        "              output = model.vocab(model.transformer.decoder(model.query_pos(model.decoder(trg_tensor)), memory,tgt_mask=mask))\r\n",
        "              mean = torch.mean(output[i][0])\r\n",
        "              std = torch.std(output[i][0])            \r\n",
        "              output = torch.tensor([((x.item()) - mean.item()) / (std.item()) for x in output[i][0]])\r\n",
        "              outputs.append(output)\r\n",
        "          for m in range(100):\r\n",
        "            if i != 0: \r\n",
        "              for iter in range(k):\r\n",
        "                old_seq, old_score = output_sequences[iter]\r\n",
        "                new =  [m]\r\n",
        "                new_sc = old_score + sigmoid(outputs[iter][m].item())\r\n",
        "                list2.append((new, new_sc))\r\n",
        "            else:\r\n",
        "              new = [] + [m]\r\n",
        "              new_sc = 0.0 +sigmoid(outputfirst[m].item())\r\n",
        "              list2.append((new, new_sc))\r\n",
        "          output_sequences = sorted(list2, key = lambda val: val[1], reverse = True)\r\n",
        "          output_sequences = output_sequences[:k]          \r\n",
        "          for n in range(k):\r\n",
        "            out_indexes[n].append(output_sequences[n][0][0])\r\n",
        "            allScores[n][-1] =  output_sequences[n][1]     \r\n",
        "            if output_sequences[n][0][0] == tokenizer.chars.index('EOS'):\r\n",
        "              if k == 1:\r\n",
        "                raise Breakit\r\n",
        "              else:\r\n",
        "                output_sequences[n], output_sequences[n-1] =  output_sequences[n-1], output_sequences[n]\r\n",
        "                k -= 1 \r\n",
        "\r\n",
        "      except Breakit:\r\n",
        "        pass\r\n",
        "\r\n",
        "      predicts = [[list(), 0.0],[list(), 0.0],[list(), 0.0]] \r\n",
        "      for b in range(k):\r\n",
        "        predicts[b][0].append(tokenizer.decode(out_indexes[b]))\r\n",
        "        predicts[b][1] = allScores[b]\r\n",
        "      predictslmao.append(predicts)\r\n",
        "      gt.append(tokenizer.decode(trg.flatten(0,1)))\r\n",
        "  return predictslmao, gt, imgs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuWdfubSymXW"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(DataGenerator(source_path,charset_base,max_text_length,'test',transform), batch_size=1, shuffle=False, num_workers=2)\r\n",
        "predicts, gt, imgs = test(model, test_loader, max_text_length)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}